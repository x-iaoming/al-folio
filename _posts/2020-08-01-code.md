---
layout: post
title: Visualizing Interstate Travel Restrictions with Python, AWS Lambda, and d3
date: 2020-08-01 15:09:00
description: My intern Hackathon project to develop a full-stack utility tool for Tripli.com
---
For my senior internship, I interned at Tripli.com, a travel startup based in Boston. The internship was during the COVID-19 pandemic, which was a challenging time for the company. I wanted to build tools that would be helpful for people and at the same time bring traffic to Tripli.com.

I noticed that, while there are plenty of data tools out there for understanding COVID infection rates, there aren’t any visual tools that synthesize travel restriction data. For travelers planning a domestic vacation, there is a market need for a tool to help them visualize the rules and regulations that they will need to comply with to avoid fines/jail time.

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <center><img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ttr1.png" width="50%"></center>
    </div>
</div>
<div class="caption">
    Interface of the Tripli (previously fly4.cheap) Travel Restrictions Visualization Map
</div>

So I built a serverless web app hosted on AWS to do just that. The application utilizes S3 to serve the frontend JS, RDS to host the PostgreSQL data, Lambda to run the web scraper and API backend. This tutorial would explain how I did it so you could build something even better.

<b>Step 1: Set up a Python scraper</b>

<b>Importing dependencies</b>

The AWS lambda service provides an easy way to set up a Python environment on the cloud without the hassle of configuring a server. However, it does not come with the dependencies we need, specifically BeautifulSoup and lxml for scraping and psycopg2 for connecting to our RDS PostgreSQL database. We will need to import these packages as layers to the lambda function.

I rely on the following pre-compiled packages:
<ul>
<li><a href="https://github.com/Beomi/aws-lambda-py3">requests_bs4_lxml</a> by Junbum Lee</li>
<li><a href="https://github.com/jkehler/awslambda-psycopg2">psycopg2</a> by Jeff Kehler - Note that Junbum Lee’s packages are for Python 3.6 so download the 3.6 version</li>
</ul>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ttr2.png">
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ttr3.png">
    </div>
    <div class="col-sm mt-3 mt-md-0">
        <img class="img-fluid rounded z-depth-1" src="{{ site.baseurl }}/assets/img/ttr4.png">
    </div>
</div>
<div class="caption">
    Adding custom packages as layers and importing layers in Lambda functions (open images for details)
</div>


<b>Scraping HTML from data sources</b>

I decided to collect and synthesize travel restrictions data from multistate.us and kayak.com. They both offer a detailed list of policies in all states but lack an interactive visualization for travelers to click and know immediately.

To scrap the data from both sources, I first get the source HTML from the website using urlopen:

{% highlight python linenos %}
  url = "https://www.multistate.us/research/covid/public?level=state"
  conn = urlopen(url)
  page_html = conn.read()
  conn.close
  page_soup = BeautifulSoup(page_html, "html.parser")
{% endhighlight %}

After inspecting the HTML elements on multistate.us, I decided to extract the openness score for every state into an array using the HTML tag ‘td’. The openness score provides us a singular measure of openness so it’s perfect for visualization on a map.

{% highlight python linenos %}
  count = 0
  data = []
  row = []

  tables = page_soup.find_all('td')
  for table in tables:
    if count == 11: # The 12th "td" is the next state
      data.append(row)
      count = 0
      row = []
    if count == 10: # The 11th "td" is the openness score
      row.append(table.a.contents[0])
      count = count + 1
    else:
      if table.a is None:
        if table.contents == []:
          row.append("")
        else:
          row.append(table.contents[0].encode('ascii', 'ignore').decode('ascii')) # save text
        row.append("")  #save blank as URL
      else:
        if table.a.contents == []:
          row.append("")
        else:
          row.append(table.a.contents[0].encode('ascii', 'ignore').decode('ascii')) #save text
        row.append(table.a.get('href'))  #save URL
      count = count + 1
  data.append(row)
{% endhighlight %}

Using a similar process, I scraped additional travel restrictions information such as mask mandate and public gatherings restrictions from Kayak.com.

All of the above scraping process happens on AWS Lambda function, and the scraped data is then uploaded to our PostgreSQL database using psycopg2. We can schedule the lambda function to trigger in fixed intervals on AWS so it gets all the information up-to-date.

<b>Step 2: Set up a backend API</b>

As we scraped and stored restrictions information in the database, I want to then serve the travel restrictions data from PostgreSQL to our frontend pages through a REST API. To quickly deploy an API, we can again use AWS Lambda function to access the data from database (as opposed to writing to the database earlier) and use AWS API Gateway to serve the content accessed by the Lambda function.

The new lambda function processes requests to the API and return data from the database. Since I am making a simple API with only GET requests to get all state’s travel restriction data, I just need to check the requests’ path in the lambda_handler function by looking at event[‘resource’].

If the path in event[‘resource’] matches, I will return a response with status code, headers, and data in the body. Getting the data from PostgreSQL database is easy through psycopg2 in the statedata() function, which will be omitted here for brevity:

{% highlight python linenos %}
def lambda_handler(event, context):
    if event["resource"] == "/statedata":
    return {
      'statusCode': 200,
      'headers': {
          'Access-Control-Allow-Headers': '*',
          'Access-Control-Allow-Origin': '*',
          'Access-Control-Allow-Methods': 'GET,OPTIONS'
      },
      'body': json.dumps(statedata())
    }
{% endhighlight %}

In the headers of the lambda response I have allowed all headers, origin, as well as GET and OPTIONS methods to enable CORS.

After completing the lambda function, I then set up a new REST API on AWS API Gateway. To configure the API with the lambda function, I created a resource and set its path to "/statedata". Under the resource, I created a Lambda function method and selected our lambda function for Lambda Proxy integration. A sample tutorial for lambda integration with API gateway can be found <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/api-gateway-create-api-as-simple-proxy-for-lambda.html">here</a>. Additionally, we will need to enable CORS on the API Gateway, following <a href="https://docs.aws.amazon.com/apigateway/latest/developerguide/how-to-cors-console.html">these instructions</a>.

<b>Step 3: Building visualizations with Javascript and d3</b>

With the backend restriction data API ready, I then worked on the frontend using Javascript and d3 visualization package.

The first step is to create a function to call the backend API via its url, which can be configured in AWS API gateway. To achieve that, I created an asynchronous function with JQuery Ajax:

{% highlight javascript linenos %}
function myAjaxCheck(callback) {
  $.ajax({
    type: 'GET',
    url: 'https://f1rob7szee.execute-api.us-east-1.amazonaws.com/v1/statedata',
    dataType: 'json',
    success: function (data) {
      callback(data);
    }
  });
}
{% endhighlight %}

I then called the above function to obtain the restrictions data for all the states, including an openness score and html content of detailed restrictions data. In order to visualize the information on a map, I had to merge the returned data from API with the geographical information of the respective state on a geoJSON file found <a href="https://gist.github.com/michellechandra/0b2ce4923dc9b5809922#file-us-states-json">here</a> by Michelle Chandra.

{% highlight javascript linenos %}
myAjaxCheck(function(returnedData){ //anonymous callback function
  data = returnedData;
  var url = "https://f4c-maps.s3.amazonaws.com/us-states.json"

  d3.json(url, function(json) {
  // Loop through each state’s restriction data from backend API
  for (var i = 0; i < data.length; i++) {
    var dataState = data[i].state; // Grab State Name
    var score = data[i].score;  // Grab data score value
    var html = data[i].html;  // Grab data html value

    // Find the corresponding state inside GeoJSON
    for (var j = 0; j < json.features.length; j++)  {
      var jsonState = json.features[j].properties.name;
      if (dataState == jsonState) {
        // Copy the restriction data into GeoJSON
        json.features[j].properties.score = score;
        json.features[j].properties.html = html;
        break;
      }
    }
  }
}
{% endhighlight %}

After binding restriction data to the GeoJSON file in d3, I simply used the GeoJSON file as the data source for a svg element I created earlier in the page’s HTML. The svg element draws the US map with every state’s geographical location, and with some small twists on the style, I set the color saturation to reflect the openness score and created a mouseover function to show the state’s name and openness score.

{% highlight javascript linenos %}
svg.selectAll("path")
            .data(json.features)
            .enter()
            .append("path")
            .attr("d", path)
            .style("stroke", "#fff")
            .style("stroke-width", "1")
            .style("fill", function(d) {
                // Get data value
                var value = d.properties.score;
                return color(value);
            })
            .on("mouseover", function(d) {
                div.transition()
                    .duration(200)
                    .style("opacity", .9);
                div.text(d.properties.name + "\n" + d.properties.score)
                    .style("left", (d3.event.pageX - leftpos) + "px")
                    .style("top", (d3.event.pageY - toppos) + "px");
            })

            // fade out tooltip on mouse out
            .on("mouseout", function(d) {
                div.transition()
                    .duration(500)
                    .style("opacity", 0);
            })
            .on("click", show_info);
{% endhighlight %}

At the end, I created the show_info function to refresh HTML content and display detailed restriction information when user clicks on a specific state.

{% highlight javascript linenos %}
function show_info(d) {
    html = d.properties.html;
    score = d.properties.score;
    name = d.properties.name;
    var template =`<h1>${name}</h1><h3><small class="text-muted"> Openness Score: ${score}</small></h3>`;
    document.getElementById("area2").innerHTML = template + d.properties.html;
}
{% endhighlight %}

Voila! Here’s all the steps it takes to create a map that visualizes openness score and displays state-wide restrictions information. All the frontend visualization scripts can be implemented in a single HTML file and I put them in this <a href="https://github.com/x-iaoming/map/blob/master/index.html">Github repo</a> if you are interested in the details.
